{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due: April 3, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: Telling Cats from Dogs using VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is based on the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io. Here you will build a classifier that can distinguish between pictures of dogs and cats. You will use a ConvNet (VGG16) that was pre-trained ImageNet. Your task will be to re-architect the network to solve your problem. To do this you will:\n",
    "0. Make a training dataset, using images from the link below, with 10,000 images of cats and 10,000 images of dogs. Use 1,000 images of each category for your validation set. The data should be orgainized into folders named ./data/train/cats/ + ./data/train/dogs/ + ./data/validation/cats/ + ./data/validation/dogs/. (No need to worry about a test set for this assignment.)  \n",
    "1. take VGG16 network architecture\n",
    "2. load in the pre-trained weights from the link below for all layers except the last layers \n",
    "3. add a fully connected layer followed by a final sigmoid layer to replace the 1000 category softmax layer that was used when the network was trained on ImageNet\n",
    "4. freeze all layers except the last two that you added\n",
    "5. fine-tune the network on your cats vs. dogs image data\n",
    "6. evaluate the accuracy\n",
    "7. unfreeze all layers\n",
    "8. continue fine-tuning the network on your cats vs. dogs image data\n",
    "9. evaluate the accuracy\n",
    "10. comment your code and make sure to include accuracy, a few sample mistakes, and anything else you would like to add\n",
    "\n",
    "Downloads:\n",
    "1. You can get your image data from:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data. \n",
    "2. You can get your VGG16 pre-trained network weights by googling\n",
    "\"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "(Note this assignment deviates from blog.keras.io in that it uses more data AND performs the fine-tuning in two steps: first freezing the lower layers and then un-freezing them for a final run of fine-tuning. The resulting ConvNet gets more than 97% accuracy in telling pictures of cats and dogs apart.)\n",
    "\n",
    "A bunch of code and network definition has been included to to get you started. This is not meant to be a difficult assignment, as you have your final projects to work on!  Good luck and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time, pickle, pandas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "class_name = {\n",
    "    0: 'cat',\n",
    "    1: 'dog',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This let's us plot samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(X, y, prediction=-1):\n",
    "    im = X\n",
    "    plt.imshow(im)\n",
    "    if prediction >= 0:\n",
    "        plt.title(\"Class = %s, Predict = %s\" % (class_name[y], class_name[prediction]))\n",
    "    else:\n",
    "        plt.title(\"Class = %s\" % (class_name[y]))\n",
    "\n",
    "    plt.axis('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define where the data comes from and how much we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = './data/train'\n",
    "validation_data_dir = './data/validation'\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 2000\n",
    "batch_size = 32\n",
    "steps_per_epoch_train = nb_train_samples / batch_size\n",
    "steps_per_epoch_val = nb_validation_samples / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras training requires specifying how the data is going to be streamed\n",
    "to to the \"fitting\" routine. Here the data is augmented with \"new\" examples which \n",
    "are sheared, zoomed, and flipped versions of the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display some sample images from this dataset. Note that these are real images and this is not an easy problem. But also note that it is made simpler by the fact that the animals, for the most part, are relatively large and centered in the photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for X_batch, Y_batch in validation_generator:\n",
    "    for i in range(len(Y_batch)):\n",
    "        show_sample(X_batch[i, :, :, :], Y_batch[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our first model. It is a small ConvNet which does surprisingly well at the dog vs. cat problem. \n",
    "But we will be able to do much better later on. This network is not particularly deep, just three convolutional layers each with max pooling and a final fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(63, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile the network using cross entropy loss on our logistic sigmoid and print out network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was havinng permission troubles with creating dirs and writing files, so I jumped out to the shell to make these manually. These dirs will hold the training history, logging, and models created during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pushd\n",
    "%mkdir -p history\n",
    "%mkdir -p models\n",
    "%mkdir -p logs\n",
    "%cd logs \n",
    "%mkdir -p ./little_convnet\n",
    "%mkdir -p ./vgg16_fine_tuning\n",
    "%popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we design the call backs that will record stuff while training. The first will create the log files that can be viewed using the command line tool Tensorboard. The second saves the \"best model\" so far, where best is based on the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir='./logs/little_convnet/', histogram_freq=0, write_graph=True, write_images=False)\n",
    "checkpoint_callback = ModelCheckpoint('./models/little_convnet_weights.{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are on to training the network. Note the use of the callbacks. Also note that the learning schedule was set back when we compiled the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 5\n",
    "\n",
    "hist_little_convet = model.fit_generator(train_generator, \n",
    "              initial_epoch=0, \n",
    "              verbose=1, \n",
    "              validation_data=validation_generator, \n",
    "              steps_per_epoch=steps_per_epoch_train, \n",
    "              epochs=nb_epoch, \n",
    "              callbacks=[tensorboard_callback, checkpoint_callback],\n",
    "              validation_steps=steps_per_epoch_val)\n",
    "                                                                                                                                   \n",
    "pandas.DataFrame(hist_little_convet.history).to_csv(\"./history/little_convet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we grab some validation batches and evaluate our accuracy. We achieve 80% with this little network, which ain't bad, but we can do MUCH better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.array([])\n",
    "losses = np.array([])\n",
    "\n",
    "i=0\n",
    "for X_batch, Y_batch in validation_generator:\n",
    "    loss, accuracy = model.evaluate(X_batch, Y_batch, verbose=0)\n",
    "    losses = np.append(losses, loss)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "       break\n",
    "       \n",
    "print(\"Validation: accuracy = %f  ;  loss = %f\" % (np.mean(accuracies), np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(validation_generator)\n",
    "predictions = model.predict_classes(X_test, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    show_sample(X_test[i, :, :, :], y_test[i], prediction=predictions[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to building a more powerful ConvNet: VGG16. We will not train it from scratch but rather load in the weights for the model from a pre-trained version, version that was trained on ImageNet. We will then chop of the last layer and replace it with one that fits our two class cat vs. dog problem. We will freeze the bottom layers of the network and only train the weights of the new last layer. Why? Because if we allow the whole model to train all the weights at once we might do damage to the carefully selected weights in the lower convolutional layers. So instead, we train only the top layer. This training produces a classifier that has 91% accuracy, which is quite an improvement over the last one. However, once this training converges, more or less, we then unfreeze the lower layers and let all the layers train. The final model gets 97% accuracy!\n",
    "\n",
    "The routine below make a VGG16 network in either Theano or Tensorflow style. The only difference is the ordering of the volume indices. Note that it does not make the last layers as these would have to be removed.\n",
    "\n",
    "#### PLEASE NOTE THAT YOUR NUMBERS WILL NOT BE EXACTLY THE SAME AS MINE. SO PLEASE DO NOT ASK ME IF YOUR NUMBERS \"ARE GOOD ENOUGH.\"  THIS IS A GUIDELINE FOR WHAT IS POSSIBLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16(framework='tf'):\n",
    "\n",
    "    if framework == 'th':\n",
    "        # build the VGG16 network in Theano weight ordering mode\n",
    "        backend.set_image_dim_ordering('th')\n",
    "    else:\n",
    "        # build the VGG16 network in Tensorflow weight ordering mode\n",
    "        backend.set_image_dim_ordering('tf')\n",
    "        \n",
    "    model = Sequential()\n",
    "    if framework == 'th':\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "    else:\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height, 3)))\n",
    "        \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the model using tensorflow format and load the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = './data/train'\n",
    "validation_data_dir = './data/validation'\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 2000\n",
    "batch_size = 32\n",
    "steps_per_epoch_train = nb_train_samples / batch_size\n",
    "steps_per_epoch_val = nb_validation_samples / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = './vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "tf_model = build_vgg16('tf')\n",
    "tf_model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make the last layer or layers. We flatten the output from the last convolutional layer, and add fully connected layer with 256 hidden units. Finally, we add the output layer which is has a scalar output as we have a binary classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Flatten object at 0x7f0130450a90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 152, 152, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 152, 152, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 77, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 77, 77, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 39, 39, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 39, 39, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 39, 39, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "print (Flatten(input_shape=tf_model.output_shape[1:]))\n",
    "top_model.add(Flatten(input_shape=tf_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "print (tf_model.summary())\n",
    "print(top_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add this model to the top of our VGG16 network, freeze all the weights except the top, and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the model on top of the convolutional base\n",
    "tf_model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in tf_model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "tf_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train for 5 epochs to get the weights for the top close to where we need them. Essentially, we want the network to be doing the right thing before we unnfreeze the lower weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# use the same data augmentation as the sample code\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# generate training and test data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 500s 799ms/step - loss: 0.4002 - acc: 0.8059 - val_loss: 0.2353 - val_acc: 0.8975\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.2488 - acc: 0.8941 - val_loss: 0.1806 - val_acc: 0.9295\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 154s 247ms/step - loss: 0.2094 - acc: 0.9137 - val_loss: 0.1630 - val_acc: 0.9330\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.1924 - acc: 0.9212 - val_loss: 0.1537 - val_acc: 0.9390\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 155s 248ms/step - loss: 0.1759 - acc: 0.9302 - val_loss: 0.1437 - val_acc: 0.9420\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 5\n",
    "vgg_callback = ModelCheckpoint('./models/vgg_weights_best.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist_little_convet = tf_model.fit_generator(train_generator, \n",
    "              initial_epoch=0, \n",
    "              verbose=1, \n",
    "              validation_data=validation_generator, \n",
    "              steps_per_epoch=steps_per_epoch_train, \n",
    "              callbacks=[vgg_callback],\n",
    "              epochs=nb_epoch, \n",
    "              validation_steps=steps_per_epoch_val)\n",
    "                                                                                                                                   \n",
    "pandas.DataFrame(hist_little_convet.history).to_csv(\"./history/vgg_weights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this, we see that it gets 91% accuracy on the validation set, so we've halved the errors from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: accuracy = 0.937500  ;  loss = 0.160700\n"
     ]
    }
   ],
   "source": [
    "# here I just print the result after 5 epochs training\n",
    "# since it's keep increasing\n",
    "accuracies = np.array([])\n",
    "losses = np.array([])\n",
    "\n",
    "i=0\n",
    "for X_batch, Y_batch in validation_generator:\n",
    "    loss, accuracy = tf_model.evaluate(X_batch, Y_batch, verbose=0)\n",
    "    losses = np.append(losses, loss)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break\n",
    "       \n",
    "print(\"Validation: accuracy = %f  ;  loss = %f\" % (np.mean(accuracies), np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can unnfreeze the lower layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model weights\n",
    "vgg_unfreeze = load_model(\"./models/vgg_weights_best.hdf5\")\n",
    "# unfreeze layers\n",
    "for layer in vgg_unfreeze.layers[:25]:\n",
    "    layer.trainable = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will let this train for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 159s 255ms/step - loss: 0.1623 - acc: 0.9348 - val_loss: 0.1494 - val_acc: 0.9390\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 158s 252ms/step - loss: 0.1543 - acc: 0.9382 - val_loss: 0.1275 - val_acc: 0.9460\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 157s 252ms/step - loss: 0.1488 - acc: 0.9396 - val_loss: 0.1280 - val_acc: 0.9460\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 159s 254ms/step - loss: 0.1361 - acc: 0.9455 - val_loss: 0.1270 - val_acc: 0.9495\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.1312 - acc: 0.9493 - val_loss: 0.1208 - val_acc: 0.9490\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.1264 - acc: 0.9506 - val_loss: 0.1197 - val_acc: 0.9490\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 158s 253ms/step - loss: 0.1225 - acc: 0.9510 - val_loss: 0.1088 - val_acc: 0.9555\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 157s 252ms/step - loss: 0.1159 - acc: 0.9528 - val_loss: 0.1243 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.1077 - acc: 0.9585 - val_loss: 0.1541 - val_acc: 0.9420\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 157s 251ms/step - loss: 0.1098 - acc: 0.9553 - val_loss: 0.1066 - val_acc: 0.9545\n"
     ]
    }
   ],
   "source": [
    "# train the unfreezed model\n",
    "nb_epoch = 10\n",
    "vgg_unfreeze_callback = ModelCheckpoint('./models/vgg_unfreeze_weights_best.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist_little_convet = vgg_unfreeze.fit_generator(train_generator, \n",
    "              initial_epoch=0, \n",
    "              verbose=1, \n",
    "              validation_data=validation_generator, \n",
    "              steps_per_epoch=steps_per_epoch_train, \n",
    "              callbacks=[vgg_unfreeze_callback],\n",
    "              epochs=nb_epoch, \n",
    "              validation_steps=steps_per_epoch_val)\n",
    "                                                                                                                                   \n",
    "pandas.DataFrame(hist_little_convet.history).to_csv(\"./history/vgg_unfreeze.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to 96% accuracy! But it looks like we stopped it a bit early..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: accuracy = 0.951562  ;  loss = 0.106700\n"
     ]
    }
   ],
   "source": [
    "# here I just print the result after 10 epochs' training\n",
    "# since it's keep increasing\n",
    "accuracies = np.array([])\n",
    "losses = np.array([])\n",
    "\n",
    "i=0\n",
    "for X_batch, Y_batch in validation_generator:\n",
    "    loss, accuracy = vgg_unfreeze.evaluate(X_batch, Y_batch, verbose=0)\n",
    "    losses = np.append(losses, loss)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break\n",
    "       \n",
    "print(\"Validation: accuracy = %f  ;  loss = %f\" % (np.mean(accuracies), np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let it go one last time and see that it pushes up just a bit higher to 97%. Also note that it looks like it is beginning to overfit as the training loss is coming way down and the training accuracy is going well beyond the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:291: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 298s 477ms/step - loss: 0.1093 - acc: 0.9564 - val_loss: 0.1074 - val_acc: 0.9555\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 295s 472ms/step - loss: 0.0866 - acc: 0.9637 - val_loss: 0.0599 - val_acc: 0.9745\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 295s 472ms/step - loss: 0.0719 - acc: 0.9716 - val_loss: 0.0537 - val_acc: 0.9775\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 295s 471ms/step - loss: 0.0619 - acc: 0.9761 - val_loss: 0.0675 - val_acc: 0.9690\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 294s 471ms/step - loss: 0.0570 - acc: 0.9785 - val_loss: 0.0475 - val_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "# train the unfreezed model\n",
    "# I train a little epochs and save the \n",
    "# best weights along the way to see if \n",
    "# I can get to 97% using the best weights\n",
    "nb_epoch = 5\n",
    "\n",
    "vgg_unfreeze = load_model(\"./models/vgg_unfreeze_weights_best.hdf5\") \n",
    "vgg_unfreeze_callback = ModelCheckpoint('./models/vgg_unfreeze_weights_best_continue.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist_little_convet = vgg_unfreeze.fit_generator(train_generator, \n",
    "              initial_epoch=0, \n",
    "              verbose=1, \n",
    "              validation_data=validation_generator, \n",
    "              steps_per_epoch=steps_per_epoch_train, \n",
    "              callbacks=[vgg_unfreeze_callback],\n",
    "              epochs=nb_epoch, \n",
    "              validation_steps=steps_per_epoch_val)\n",
    "                                                                                                                                   \n",
    "pandas.DataFrame(hist_little_convet.history).to_csv(\"./history/vgg_unfreeze_continue.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! 97% accuracy! And we are done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: accuracy = 0.978125  ;  loss = 0.052629\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.array([])\n",
    "losses = np.array([])\n",
    "# Note: I load the best weight here to see if I can push to 97%\n",
    "vgg_unfreeze = load_model(\"./models/vgg_unfreeze_weights_best_continue.hdf5\") \n",
    "i=0\n",
    "for X_batch, Y_batch in validation_generator:\n",
    "    loss, accuracy = vgg_unfreeze.evaluate(X_batch, Y_batch, verbose=0)\n",
    "    losses = np.append(losses, loss)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break\n",
    "       \n",
    "print(\"Validation: accuracy = %f  ;  loss = %f\" % (np.mean(accuracies), np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
