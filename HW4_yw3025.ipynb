{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: March 20, 2018\n",
    "\n",
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide three networks for classifying handwritten digits from the MNIST dataset. The networks are implemented and tested using the Tensorflow framework. The third and final network is a convolutional neural network (CNN aka ConvNet) which achieves 99.25% accuracy on this dataset. \n",
    "\n",
    "Your task is to re-implement all three networks using the Keras wrapper around Tensorflow OR\n",
    "re-implement using Pytorch. You will likely find several Keras or Pytorch implementations on the internet. It is ok to study these. However, you must not cut and paste this code into your assignment--you must write this yourself. Furthermore, you need to comment every line of code and succintly explain what it is doing! \n",
    "\n",
    "Here is what is required:\n",
    "\n",
    "a) A FULLY commented re-implementation of the ConvNet below using the Keras wrapper on Tensorflow OR Pytorch.\n",
    "\n",
    "b) your network trained on the same MNIST data as used here.\n",
    "\n",
    "c) an evaluation of the accuracy on the MNIST test set.\n",
    "\n",
    "d) plots of 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "\n",
    "e) have your training record a log of the data using the Keras API and then use Tensorboard (a command line tool) to display plots of the validation loss and validation accuracy. you can zip up a screenshot of this with your notebook before submission.\n",
    "\n",
    "f) have your training continually save the best model so far (as determined by the validation loss) using the Keras API or Pytorch.\n",
    "\n",
    "g) after training, load the saved weights using the best model so far. re-run you accuracy evaluation using these saved weights.\n",
    "\n",
    "Below we include the Tensorflow examples shown in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Convolutional Neural Network in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a python and tensorflow-based solution to the handwritten digits recognition problem. It is based on tensorflow tutorials and Yann LeCun's early work on CNN's. This toturial compares a simple softmax regressor, a multi-layer perceptron (MLP), and a simple convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the MNIST digit dataset directly from tensorflow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import tensorflow and begin an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create placeholders for the data. Data will be dumped here when it is batched from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(4):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the parameters (weights) for our linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use tensorflows initializer to initialize these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our linear layer as a function of the input and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_regressor = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create our loss function. Note that the cross entropy is $ H_{\\hat{y}}(y) = -\\sum_i \\hat{y}_{i} \\, \\log(y_{i})$ where $\\hat{y}$ is the true probability distribution and is expressed as a one-hot vector, $y$ is the estimated probability distribution, and $i$ indexes elements of these two vectors. Also note that this reduces to $ H_{\\hat{y}}(y) = -\\, \\log(y_{i^*})$ where $i^*$ is the correct label. And if we sum this over all of our samples indexed by $j$, then $H_{\\hat{y}}(y) = -\\sum_j  \\log(y^{(j)}_{i^*})$. This is precisely the same loss function as we used before, but we called the MLE loss. They are one and the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_regressor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell tf to use gradient descent with a step size of 0.5 and to minimize the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]],\n",
    "                 [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]],\n",
    "                 [[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(a_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train by grabbing mini-batches with 100 samples each and pushing these through the network to update our weights (W and b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define how to compute correct predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_regressor,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from these correct predictions how to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out some test images and the corresponsing predictions made by the network. But first, let's add an output to the computation graph that computes the softmax probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probs_regressor = tf.nn.softmax(logits=y_regressor, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print (\"Label = \", label)\n",
    "    print (\"Class probabilities = \", y_probs_regressor.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Multi-Layer Perceptron on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create placeholders for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the first and only fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h = weight_variable([784, 512])\n",
    "b_h = bias_variable([512])\n",
    "h = tf.nn.relu(tf.matmul(x, W_h) + b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_out = weight_variable([512, 10])\n",
    "b_out = bias_variable([10])\n",
    "y_MLP = tf.matmul(h, W_out) + b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use cross entropy loss on a softmax distribution on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training. Note this softmax MLP network does quite a bit bettter than our softmax regressor. The non-linear layer really helps makes sense of the data! But we can do better still..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_MLP,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1]})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Convolutional Neural Network: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make our first CNN. It's quite simple network, but it's surprisingly good at this handwritten digit recognition task. This a variant on Yann LeCun's CNN network that really helped to move deep learning forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define how the convolution is to be computed and the extent and type of pooling. The convolution will use a 5x5 kernel and will pad the image with zeros around the edges and use a stride of 1 pixel so that the resulting image (after convolution) has the same size as the original input image. The network will learn the weights for a stack of 32 separate kernels along with 32 bias variables. Finally, after the ReLu is performed the result will be under go 2x2 max pooling, thus halfing both dimensions of the image. The choices for the stride, padding, and pooling are not parameters that the network needs to estimate. Rather these are termed \"hyperparamters\" that are usually set by the network designer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the weight and bias variables for the first convolutional layer as described above. Note the output has depth 32, so there will be 32 feature images after this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike for our softmax regressor above, here we need keep the images as images and not collapse these into vectors; this allows us to perform the 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define are first layer of our CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And wasting no time, we define are second layer. The second layer will have to process 32 feature images coming out of the first layer. Note that the images input to this layer have $\\frac{1}{4}$ the number of pixels as the original input images due to the 2x2 pooling in the previous layer. Note that convolution layer NOT fully connected as our previous hidden layers have been. A unit in the output layer has a limited \"receptive field.\" Its connections to the input layer are spatially limited by the kernel (or filter) size. Also, because of weight sharing in convolutional layers, the number of parameters for a convolutional is the size of the kernel x the depth of the input layer x depth of the output layer + depth of the output layer. So for the second layer of our ConvNet, we have 5 x 5 x 32 x 64 + 64 = 51,264 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pooling stage of our second convolutional layer, we have 64 7x7 \"feature\" images. In one penultimate fully connected hidden layer, we are going to map these feature imges to a 1024 dimensional feature space. Note we need to flatten these feature images to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is added here, although it is not really needed for such small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a final linear output layer mapping features to scores topped off with a softmax cross entropy loss function, as explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an output to compuational graph that computes the label probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probs = tf.nn.softmax(logits=y_conv, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we step through some test examples and see how well the network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print (\"Label = \", label)\n",
    "    print (\"Class probabilities = \", y_probs.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Implementation start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/yuwang/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import library \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras library and some utility\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the shape of the image\n",
    "rows, cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to feed the data for the network\n",
    "def get_data(input_shape):\n",
    "    \"\"\"\n",
    "    input shape: the shape required by the first layer of keras\n",
    "    for Q1 and Q2 it's (784,) for Q3 it's (28, 28, 1)\n",
    "    \"\"\"\n",
    "    # load the data from mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    # turn the data into float32 format\n",
    "    X_train = X_train.astype('float32') \n",
    "    X_test = X_test.astype('float32') \n",
    "    # normalize the data (data read from tensorflow is normalized but not keras)\n",
    "    X_train /= 255 \n",
    "    X_test /= 255\n",
    "    # reshape the data into the format (batchsize, input_format)\n",
    "    X_train = X_train.reshape((X_train.shape[0],) + input_shape)\n",
    "    X_test = X_test.reshape((X_test.shape[0],) + input_shape)\n",
    "    # reshape the label into one-hot encoding vector\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to train the network\n",
    "def train(model, X_train, y_train, model_name, batch_size, epochs):\n",
    "    \"\"\"\n",
    "    model: the defined model\n",
    "    X_train: training sample feature vector\n",
    "    y_train: training sample label\n",
    "    model_name: str passed as the prefix of model weights and tensorboard file\n",
    "    batch_size: batch_size\n",
    "    epochs: epochs\n",
    "    \"\"\"\n",
    "    # define the file to save the best weights\n",
    "    filepath= model_name + \".weights.best.hdf5\"\n",
    "    # define the file to store tensorboard file\n",
    "    log_dir = './logs/' + model_name\n",
    "    # define the callback for model checkpoint to store the best model weights after every epoch\n",
    "    # best model determined by the validation loss\n",
    "    ckpt_callback = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    # define the callback for tensorboard visualization\n",
    "    tfboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0,  write_graph=True, write_images=True)\n",
    "    # define the callback list to put in the argument of model.fit\n",
    "    callbacks_list = [ckpt_callback, tfboard_callback]\n",
    "    # fit the model with training data \n",
    "    # I use the validation_split provided by keras API to do test_validation split here, it's much simpler\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose = 1, validation_split=0.2)\n",
    "    return filepath, log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evalute function to get the accuracy of the model\n",
    "def evaluate(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    model: the predefined and trained model architecture\n",
    "    X_test: testing sample feature vector\n",
    "    y_test: testing sample label\n",
    "    \"\"\"\n",
    "    # get the loss and accuracy of the model\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "    # print the loss and accuracy\n",
    "    print (\"Test Loss: %f\" % loss)\n",
    "    print (\"Test Accuracy: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to plot 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "def plot_digits(model, X_test, y_test, input_shape):\n",
    "    \"\"\"\n",
    "    model: the predefined and trained model architecture\n",
    "    X_test: testing sample feature vector\n",
    "    y_test: testing sample label\n",
    "    input_shape: the pre-processed input shape \n",
    "    \"\"\"\n",
    "    # the ten randomly selected sample\n",
    "    plot_list_X = np.random.randint(0, X_test.shape[0], size = 10)\n",
    "    for plot_X in plot_list_X:\n",
    "        # get the sample data\n",
    "        batch = X_test[plot_X]\n",
    "        # reshape the data into input shape for the model\n",
    "        batch = batch.reshape((1, ) + input_shape)\n",
    "        # get the softmax probability\n",
    "        class_probability = model.predict(batch, batch_size=1, verbose=1)\n",
    "        # get the image for display\n",
    "        image = np.asarray(batch).reshape((rows, cols))\n",
    "        # get the predicted label\n",
    "        label = np.argmax(y_test[plot_X])\n",
    "\n",
    "        # show the image\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        # print the result\n",
    "        print (\"Label = \", label)\n",
    "        print (\"predicted Label = \", np.argmax(class_probability))\n",
    "        print (\"Class probabilities = \", class_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get the result of stored best model\n",
    "def get_best_model(filepath, X_test, y_test):\n",
    "    # load the model weights from file\n",
    "    best_model = keras.models.load_model(filepath)\n",
    "    # get the loss and accuracy\n",
    "    best_loss, best_acc = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "    # print the result\n",
    "    print (\"Best Test Loss: %f\" % best_loss)\n",
    "    print (\"Best Test Accuracy: %f\" % best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the softmax model\n",
    "def get_Model(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: the required shape for the keras API\n",
    "    \"\"\"\n",
    "    # use the sequential model, which is a linear stack of layers\n",
    "    model = Sequential()\n",
    "    # add a dense layer with ten neurons and use softmax function to get class probabilities\n",
    "    model.add(Dense(10, input_shape = input_shape, activation='softmax', use_bias=True, \\\n",
    "                    kernel_initializer = keras.initializers.Zeros(), \\\n",
    "                   bias_initializer = keras.initializers.Zeros()))\n",
    "    # use vallina SGD optimizer\n",
    "    sgd = keras.optimizers.SGD(lr=0.5)\n",
    "    # configure the model for training\n",
    "    # use cross entropy loss and use accuracy metrics\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "46900/48000 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8820Epoch 00001: val_loss improved from inf to 0.31174, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.4143 - acc: 0.8824 - val_loss: 0.3117 - val_acc: 0.9096\n",
      "Epoch 2/20\n",
      "46200/48000 [===========================>..] - ETA: 0s - loss: 0.3162 - acc: 0.9093Epoch 00002: val_loss improved from 0.31174 to 0.29511, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3153 - acc: 0.9097 - val_loss: 0.2951 - val_acc: 0.9162\n",
      "Epoch 3/20\n",
      "46100/48000 [===========================>..] - ETA: 0s - loss: 0.2999 - acc: 0.9150Epoch 00003: val_loss improved from 0.29511 to 0.28232, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2995 - acc: 0.9152 - val_loss: 0.2823 - val_acc: 0.9198\n",
      "Epoch 4/20\n",
      "46600/48000 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9176Epoch 00004: val_loss improved from 0.28232 to 0.28223, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2906 - acc: 0.9178 - val_loss: 0.2822 - val_acc: 0.9237\n",
      "Epoch 5/20\n",
      "46300/48000 [===========================>..] - ETA: 0s - loss: 0.2842 - acc: 0.9201Epoch 00005: val_loss improved from 0.28223 to 0.27536, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2848 - acc: 0.9201 - val_loss: 0.2754 - val_acc: 0.9241\n",
      "Epoch 6/20\n",
      "46500/48000 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9211Epoch 00006: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2798 - acc: 0.9212 - val_loss: 0.2789 - val_acc: 0.9227\n",
      "Epoch 7/20\n",
      "46300/48000 [===========================>..] - ETA: 0s - loss: 0.2771 - acc: 0.9215Epoch 00007: val_loss improved from 0.27536 to 0.27355, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2772 - acc: 0.9214 - val_loss: 0.2735 - val_acc: 0.9252\n",
      "Epoch 8/20\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.2738 - acc: 0.9237Epoch 00008: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2736 - acc: 0.9237 - val_loss: 0.2748 - val_acc: 0.9238\n",
      "Epoch 9/20\n",
      "46600/48000 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9230Epoch 00009: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2715 - acc: 0.9228 - val_loss: 0.2812 - val_acc: 0.9232\n",
      "Epoch 10/20\n",
      "45900/48000 [===========================>..] - ETA: 0s - loss: 0.2688 - acc: 0.9244Epoch 00010: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2690 - acc: 0.9242 - val_loss: 0.2773 - val_acc: 0.9230\n",
      "Epoch 11/20\n",
      "46800/48000 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9244Epoch 00011: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2671 - acc: 0.9245 - val_loss: 0.2809 - val_acc: 0.9225\n",
      "Epoch 12/20\n",
      "45900/48000 [===========================>..] - ETA: 0s - loss: 0.2651 - acc: 0.9270Epoch 00012: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.2657 - acc: 0.9268 - val_loss: 0.2810 - val_acc: 0.9221\n",
      "Epoch 13/20\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.9261Epoch 00013: val_loss did not improve\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2642 - acc: 0.9260 - val_loss: 0.2745 - val_acc: 0.9248\n",
      "Epoch 14/20\n",
      "47900/48000 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9265Epoch 00014: val_loss did not improve\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2630 - acc: 0.9264 - val_loss: 0.2777 - val_acc: 0.9244\n",
      "Epoch 15/20\n",
      "47200/48000 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9271Epoch 00015: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2617 - acc: 0.9271 - val_loss: 0.2753 - val_acc: 0.9249\n",
      "Epoch 16/20\n",
      "47500/48000 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9272Epoch 00016: val_loss did not improve\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.2605 - acc: 0.9270 - val_loss: 0.2752 - val_acc: 0.9253\n",
      "Epoch 17/20\n",
      "45900/48000 [===========================>..] - ETA: 0s - loss: 0.2598 - acc: 0.9268Epoch 00017: val_loss did not improve\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2601 - acc: 0.9271 - val_loss: 0.2799 - val_acc: 0.9236\n",
      "Epoch 18/20\n",
      "47300/48000 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9276Epoch 00018: val_loss improved from 0.27355 to 0.27141, saving model to softmax.weights.best.hdf5\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2585 - acc: 0.9278 - val_loss: 0.2714 - val_acc: 0.9256\n",
      "Epoch 19/20\n",
      "46700/48000 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.9278Epoch 00019: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.2584 - acc: 0.9279 - val_loss: 0.2731 - val_acc: 0.9255\n",
      "Epoch 20/20\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9278Epoch 00020: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2561 - acc: 0.9277 - val_loss: 0.2718 - val_acc: 0.9258\n",
      "softmax.weights.best.hdf5 ./logs/softmax\n"
     ]
    }
   ],
   "source": [
    "# define input shape\n",
    "input_shape = (784,)\n",
    "# get the shaped data\n",
    "X_train, X_test, y_train, y_test = get_data(input_shape)\n",
    "# configure the model\n",
    "model = get_Model(input_shape)\n",
    "# train the model on train dataset\n",
    "filepath, log_dir = train(model, X_train, y_train, \"softmax\", 100, 20)\n",
    "print (filepath, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Test Loss: 0.273234\n",
      "Test Accuracy: 0.924400\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model on test dataset\n",
    "evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124132cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  8\n",
      "predicted Label =  3\n",
      "Class probabilities =  [[  2.76367995e-04   9.89590080e-06   1.29556036e-04   9.07509029e-01\n",
      "    1.66209647e-05   4.21560630e-02   9.90638182e-06   2.31323618e-08\n",
      "    4.94518653e-02   4.40765521e-04]]\n",
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nokzByoYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d510f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  9\n",
      "predicted Label =  9\n",
      "Class probabilities =  [[  1.70327275e-09   3.17045851e-05   6.72737173e-08   2.61497148e-03\n",
      "    4.66641691e-03   4.25087940e-03   1.61785906e-07   1.51970992e-02\n",
      "    1.19366357e-03   9.72045064e-01]]\n",
      "\r",
      "1/1 [==============================] - 0s 798us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0KJH0L9DzD/AGOyWdZCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125534a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  3\n",
      "predicted Label =  3\n",
      "Class probabilities =  [[  4.13179491e-03   6.26983412e-04   4.11716895e-03   9.39860165e-01\n",
      "    9.32821713e-05   3.34457904e-02   3.31012357e-04   2.52840010e-07\n",
      "    1.71198696e-02   2.73840735e-04]]\n",
      "\r",
      "1/1 [==============================] - 0s 755us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAByBJREFUeJzt3U+InHcdx/GZ2U0yDW2NaNMqlCYmxA0VxcRDE6wEJOC/\ni8X1UA89CEvUQq0aCSIpUihYENTGShS0WlTC1ioi/iEiHmKTWkgb6x8KqbXFahpsm2IbNnZ3xkNz\n8fB8Z7Ozmd3s5/W6fvJkHlreeQ6/fWbb/X6/BeTpLPUNAEtD/BBK/BBK/BBK/BBK/BBK/BBK/BBK\n/BBqfJQftrsz6ccJ4SI73Jtuz+fPefJDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDqJH+\nim6Wn50n/lvud1z1l3J/uTdT7tuOTDVu6x+4rLz2dUf+Xu6zp54rd2qe/BBK/BBK/BBK/BBK/BBK\n/BBK/BDKOX+4s73V5T7X75X7Ze36+r/eeF/zeGN5aeunr6wr988d+Wi5v3XqscatPztbf3gAT34I\nJX4IJX4IJX4IJX4IJX4IJX4I1e73+yP7sN2dydF9GPPSfuf15X5y76py37/t5+X+sStOX/A9LZYt\n059s3DZ/+tgI72S0Dvem2/P5c578EEr8EEr8EEr8EEr8EEr8EMorveH6j/653DfdXF9/6Lod5f6V\nD1/buD14+93ltRvG15b7WLt+dl2+4aVyT+fJD6HED6HED6HED6HED6HED6HED6Gc8zOUuVP1K7tz\n3eZz/rXzevG02T9mXy737oP1V3+n8+SHUOKHUOKHUOKHUOKHUOKHUOKHUM75KfV3vKPcZ+98sdxP\nbD1QrPX7+oO89/695b7h+0eH+vtXOk9+CCV+CCV+CCV+CCV+CCV+CCV+COWcP9wz+3eW+4FbDpb7\nru6ri3k7/2fiB58q9813PlruvcW8mRXIkx9CiR9CiR9CiR9CiR9CiR9CiR9COee/BLS3X1/uT910\nZeP2ofc9XF77s2u+Vu7jrbFyH+TZubON2+QX6/fxNx06Xu69c+cWdE+8xpMfQokfQokfQokfQokf\nQokfQjnqWwae3Ve/VvuHW79a7mvaw/xvHO4ob5D/9Jr//u4Lc+W1fUd5F5UnP4QSP4QSP4QSP4QS\nP4QSP4QSP4Ryzr8MrN75fLkPd46/tCZWrWncfnPwm+W179lbf3X3lT88tqB74jWe/BBK/BBK/BBK\n/BBK/BBK/BBK/BDq0j1AXkHeNHWm3DffNVXunVXN78Vv+G7973u71y/3QZ68uf4+gJMfbP4V351W\nu7z21jumy/3bL95U7mt++Ui5p/Pkh1Dih1Dih1Dih1Dih1Dih1Dih1Dtfn+4c94LsbszOboPYyQ6\n3W65v/3oTOP25asfK6+d6/fKfev99fv+G/cdLfeV6nBvuv4BivM8+SGU+CGU+CGU+CGU+CGU+CGU\n+CGU9/kZSm+m+Ry/1Wq1fv2dnY3bXfuOL/btcAE8+SGU+CGU+CGU+CGU+CGU+CGUoz4uqu77Ty/1\nLdDAkx9CiR9CiR9CiR9CiR9CiR9CiR9COec/b/yaq8v9b3s2NW6rX6r/7t6qen/z3Q/Vf2AZG3vj\nG8r9J2+7r/na9uXltYO+unvs7Ly+oZoGnvwQSvwQSvwQSvwQSvwQSvwQSvwQyjn/ef88+Ppy/9O7\nDjRuvz9X/xv6+f17FnRPl4KTn9lS7uvH1jZug87xfzdT/4DExnufKPe5csWTH0KJH0KJH0KJH0KJ\nH0KJH0KJH0I555+nsXbzv5PfOrWrvHbdofpXUfcXckOLpV2/E//8x28o98dv+fqADxhrXor/pq1W\nq7Vneqrc3/LvowM+m4onP4QSP4QSP4QSP4QSP4QSP4Ry1DdP1eun37vut+W1tz20o9zPvLqu3I89\ntbHcx5/sNm7t2foo74YPPF7uv7j2G+VeHeUN8tl/bSv3Lfc8Xe6zC/5kWi1Pfoglfgglfgglfggl\nfgglfgglfgjV7vdH90Lp7s7kkr69Wul0m8/KW61Wa/uxVxq3L111YrFv54JUr8YO+nrsYc0O+ILs\niV99onHb+oVnymvnnju9oHtKd7g3Pa/fXe7JD6HED6HED6HED6HED6HED6HED6G8z39eb2am3I9/\nZHPjNjH17vLaKyZeKPdHtv+o3AcZ5iz/3jP1dwXc88dd5b7+x/XPR2x54OHGza/QXlqe/BBK/BBK\n/BBK/BBK/BBK/BBK/BDK+/ywwnifHyiJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJ\nH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KJH0KN9Fd0\nA8uHJz+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+E\nEj+EEj+EEj+EEj+EEj+E+h8k3P0/tv2zPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12214e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  3\n",
      "predicted Label =  3\n",
      "Class probabilities =  [[  1.45787490e-05   1.08805648e-06   5.65045557e-05   9.88854647e-01\n",
      "    2.61258697e-06   1.05692400e-02   4.59639260e-08   3.88621624e-09\n",
      "    4.99872724e-04   1.40623388e-06]]\n",
      "\r",
      "1/1 [==============================] - 0s 697us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1233dd470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  5\n",
      "predicted Label =  5\n",
      "Class probabilities =  [[  2.46744463e-03   1.16999811e-02   3.90658062e-03   2.20997930e-02\n",
      "    6.98171509e-03   8.61621737e-01   3.15967845e-05   6.82421320e-04\n",
      "    8.26993585e-02   7.80934328e-03]]\n",
      "\r",
      "1/1 [==============================] - 0s 694us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUOKHUOKHUP8DpmhLeUuCBj4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12aa9ba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  8\n",
      "predicted Label =  8\n",
      "Class probabilities =  [[  2.20017796e-06   6.35356088e-08   4.71228827e-03   2.19509471e-03\n",
      "    1.18986227e-05   2.11692197e-04   2.06989881e-07   6.64462448e-07\n",
      "    9.92304504e-01   5.61375578e-04]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVBrR75FQ4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1270057f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  6\n",
      "predicted Label =  6\n",
      "Class probabilities =  [[  4.26709192e-08   1.23425778e-07   6.79359713e-04   2.95783309e-07\n",
      "    1.65245699e-04   9.36124707e-07   9.99093771e-01   7.67595850e-07\n",
      "    4.16733310e-05   1.77068068e-05]]\n",
      "\r",
      "1/1 [==============================] - 0s 973us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1292775c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  0\n",
      "predicted Label =  0\n",
      "Class probabilities =  [[  9.92174506e-01   3.84863989e-14   4.82189655e-03   7.57051050e-04\n",
      "    4.07153686e-11   2.22961581e-03   3.50025266e-06   4.56730598e-10\n",
      "    1.33718522e-05   2.68050859e-10]]\n",
      "\r",
      "1/1 [==============================] - 0s 524us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1255acb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  4\n",
      "predicted Label =  4\n",
      "Class probabilities =  [[  3.62008379e-08   6.48404921e-07   1.22569210e-04   4.81330353e-04\n",
      "    9.88172710e-01   2.00686976e-04   8.01230490e-04   4.03796221e-05\n",
      "    1.04792020e-03   9.13259014e-03]]\n",
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh1Dih1Dih1Dih1Dih1Dih1D/A9MBuf37CYvxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1223b62e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  7\n",
      "predicted Label =  7\n",
      "Class probabilities =  [[  1.24898725e-04   1.62897216e-08   1.30813178e-05   8.64558853e-04\n",
      "    1.23930178e-04   3.33152665e-03   3.88626660e-07   7.52221048e-01\n",
      "    2.32371516e-04   2.43088216e-01]]\n"
     ]
    }
   ],
   "source": [
    "# plot 10 randomly selected digits from test dataset\n",
    "plot_digits(model, X_test, y_test, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Best Test Loss: 0.270258\n",
      "Best Test Accuracy: 0.923900\n"
     ]
    }
   ],
   "source": [
    "# re-run the accuracy evaluation on the test model using the save best weights\n",
    "get_best_model(filepath, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 Softmax Multi-Layer Perceptron on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mlp model\n",
    "def get_Model(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: the required shape for the keras API\n",
    "    \"\"\"\n",
    "    # kernal_intializer with truncated normal std_dev 0.1 and mean 0.0\n",
    "    kernel_initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None)\n",
    "    # bias_initializer with constant 0.1\n",
    "    bias_initializer = keras.initializers.Constant(value=0.1)\n",
    "    # use the sequential model, which is a linear stack of layers\n",
    "    model = Sequential()\n",
    "    # add a dense layer with 512 neurons and use relu as activation function after affine layer\n",
    "    model.add(Dense(512, input_shape = input_shape, activation='relu', \\\n",
    "                    kernel_initializer = kernel_initializer, \\\n",
    "                    bias_initializer = bias_initializer))\n",
    "    # add a dense(output) layer with 10 neurons and use softmax to get class probabilities\n",
    "    model.add(Dense(10, activation='softmax',  \\\n",
    "                    kernel_initializer = kernel_initializer, \\\n",
    "                    bias_initializer = bias_initializer))\n",
    "    # use adam optimizer\n",
    "    adam = keras.optimizers.Adam(lr=1e-4)\n",
    "    # fit the model with training data \n",
    "    # I use the validation_split provided by keras API to do test_validation split here, it's much simpler\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "22850/48000 [=============>................] - ETA: 7s - loss: 0.8115 - acc: 0.7680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0bf1edfa6a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# train the model on train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mlp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2f49b61cd234>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, model_name, batch_size, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# fit the model with training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# I use the validation_split provided by keras API to do test_validation split here, it's much simpler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define input shape\n",
    "input_shape = (784,)\n",
    "# get the shaped data\n",
    "X_train, X_test, y_train, y_test = get_data(input_shape)\n",
    "# configure the model\n",
    "model = get_Model(input_shape)\n",
    "# train the model on train dataset\n",
    "filepath, log_dir = train(model, X_train, y_train, \"mlp\", 50, 20)\n",
    "print (filepath, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 97us/step\n",
      "Test Loss: 0.071363\n",
      "Test Accuracy: 0.978600\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model on test dataset\n",
    "evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13272de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  8\n",
      "predicted Label =  8\n",
      "Class probabilities =  [[  5.77793147e-09   1.66748993e-11   1.69146108e-06   6.11855144e-09\n",
      "    1.01746316e-07   4.83211124e-07   6.86456971e-08   1.15823862e-09\n",
      "    9.99997258e-01   3.68980579e-07]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABTFJREFUeJzt3S9vVFkcgOGWrOIjYBCt2VU4uiE7jqARBFe7JKv4Gmuw\nYOsIonqDa0LCOhQKQjBNsAgks4Zkzfaebqd3Op33eeyZP5eSN0f85ty7u1wud4CeG1d9AcDVED9E\niR+ixA9R4oco8UOU+CFK/BAlfoj6aZ1fdv/GIz8nhJm9/v5q9zyvs/NDlPghSvwQJX6IEj9EiR+i\nxA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPgh\nSvwQJX6IEj9EiR+i1vqIbi7mr9N3k+t7L5+cubb/9O1lXw5bws4PUeKHKPFDlPghSvwQJX6IEj9E\nmfNvgA/PDgavmJ7z89++Pbx75trpYnfyvbdOlpPrN4//vtA1bRI7P0SJH6LED1HihyjxQ5T4IUr8\nEGXOvwE+Pn5+1ZewlaZm+aO/+eHBYnL9y/GFLmmj2PkhSvwQJX6IEj9EiR+ixA9RRn1rMPeR3dHx\n06p7B+8v/N6j2yeT6w927lz4szeFnR+ixA9R4oco8UOU+CFK/BAlfogy51+DuY/sbsNtpOcwmtXX\n2fkhSvwQJX6IEj9EiR+ixA9R4ococ/5LMPd5/b2XTybX93fervT5NNn5IUr8ECV+iBI/RIkfosQP\nUeKHKHP+SzD3eX335V+/wm8r7PwQJX6IEj9EiR+ixA9R4oco8UOUOf85TZ/ZX+28/oj78jMHOz9E\niR+ixA9R4oco8UOU+CHKqO+c5jy2e/h5MXjF19m++zqb85bp9w7eT65/enh3cv06jGft/BAlfogS\nP0SJH6LED1HihyjxQ5Q5/w9zP2Z7yqc/f55cv7mz+TPjOYz+T+b87cXR7ZPJ9b3FL5Pr+8eXeTXz\nsPNDlPghSvwQJX6IEj9EiR+ixA9R5vw/jM5vr2L4uOfjq3vc87fBufTTxe7k+ip/t9Esfe5bok8Z\n3WNh/6lHdAPXlPghSvwQJX6IEj9EiR+ixA9RmTn/aJ59dPvFbN89moW/GZxbH71/PC+fcnWz9JHR\nrH21f/e0N28H5/V3zPmBa0r8ECV+iBI/RIkfosQPUeKHqMycf3QufU7DefSM8+qr9tsfv5+5Nn6G\n/dfp5dP/fz38y84PUeKHKPFDlPghSvwQJX6Iyoz6ttnU0dfR0dSRWyfLyfXRuK76ePHrwM4PUeKH\nKPFDlPghSvwQJX6IEj9EZeb8o0cqHx7Md5vo0S2oR7P4VWbt23CLaeZh54co8UOU+CFK/BAlfogS\nP0SJH6Iyc/6RL79O3yb6wc6dFT59+rPN4jfP6LcV28DOD1HihyjxQ5T4IUr8ECV+iBI/RJnzs7E+\nPDsYvOLdbN89fnz49WfnhyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EOdLL\nxhrePvvxeq5jW9n5IUr8ECV+iBI/RIkfosQPUeKHKHN+Ntbo9tl7iyeT6x8fPz9z7fDzYvDt049V\n3wZ2fogSP0SJH6LED1HihyjxQ5T4IWp3uRycmb5E9288Wt+XQdTr7692z/M6Oz9EiR+ixA9R4oco\n8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6I\nEj9EiR+ixA9R4oco8UOU+CFqrY/oBjaHnR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hihyjx\nQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6I+ge+DaH/EsPPfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132b4c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  4\n",
      "predicted Label =  4\n",
      "Class probabilities =  [[  2.92765293e-07   1.19318766e-09   1.16083193e-07   3.36805750e-10\n",
      "    9.99981999e-01   4.39995738e-08   9.50273989e-06   7.07592562e-08\n",
      "    9.01817486e-07   7.12611381e-06]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13277f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  3\n",
      "predicted Label =  3\n",
      "Class probabilities =  [[  2.05246717e-08   1.44127478e-06   5.50772370e-07   9.99566257e-01\n",
      "    1.57148634e-07   3.73587362e-04   3.93323499e-11   2.95522739e-07\n",
      "    4.49789331e-05   1.28716583e-05]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1331a76a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  5\n",
      "predicted Label =  0\n",
      "Class probabilities =  [[  9.54649448e-01   7.12603764e-07   3.14655388e-03   4.69249813e-03\n",
      "    6.69180066e-04   1.39336828e-02   2.28506587e-02   8.42332781e-07\n",
      "    4.61889249e-05   1.02604226e-05]]\n",
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4QSP4QSP4T6F9R2qqx5aBXVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1332d5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  7\n",
      "predicted Label =  7\n",
      "Class probabilities =  [[  4.91858316e-07   4.30515365e-06   9.15177108e-04   1.18107314e-03\n",
      "    3.26308827e-06   1.01401433e-07   7.63633011e-07   9.97843981e-01\n",
      "    7.43692817e-06   4.33743589e-05]]\n",
      "\r",
      "1/1 [==============================] - 0s 993us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABYJJREFUeJzt3SGPFGccwOE5gkLUNsFcGjCtquMI4RxBIwgOCwmqph+i\nBkVSLI4gThMcpCk4FDWQBkOCRSDZfoBmZ5bszc7d/Z7Hvrc7A8kvr/jvO7O3Wq0GoOfc0jcALEP8\nECV+iBI/RIkfosQPUeKHKPFDlPgh6vwuL3bj3G0/J4SZvfj2bG+Tv7PzQ5T4IUr8ECV+iBI/RIkf\nosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LOL30DnG3vHx6sXftw589Zr33z4q+zfv9pZ+eHKPFDlPghSvwQJX6IEj9EGfUxamxUNwzDcO3g\n3ej68/15x3mj1/70drbvvv7g3uj6haM3s137uNj5IUr8ECV+iBI/RIkfosQPUeKHqL3VarWzi904\nd3t3F2MYhmH4euvK6PpPv/8zuv5k/+Vx3s53ufvxcKvPL3nvSx4nfvHt2d4mf2fnhyjxQ5T4IUr8\nECV+iBI/RIkfopznPwOWfDz2NrY9E//j3z8c5+18l8l7H5znB04o8UOU+CFK/BAlfogSP0SJH6LM\n+U+AqTP3rx49nviG+Z5PP2XqzP3nq1/Wrk3NwqfeGTDnOwGm/l2n4bn8U+z8ECV+iBI/RIkfosQP\nUeKHKPFDlDn/Dmz77Pwlzfke+qnz+EvO8cd+n3BW2PkhSvwQJX6IEj9EiR+ixA9RRn3HYPsjufPZ\ndqQ1dex2mzHmkq/Q/uv1L6Prl4fXO7qT5dj5IUr8ECV+iBI/RIkfosQPUeKHKHP+DY3Ns5ec4w/D\nMFx6en/t2uXf5p1XTx1HXnKWP+biy9XSt7A4Oz9EiR+ixA9R4oco8UOU+CFK/BBlzr+hT4d7i117\nbI4/DNvN8k/yswi2Nfr7h6Ozf15/ip0fosQPUeKHKPFDlPghSvwQJX6IMuff0Ic7870uets5/vuH\nB2vXrh28G/3sk/3TO8efMvezDE47Oz9EiR+ixA9R4oco8UOU+CFK/BBlzn8CTP6G4M7UN7w9rls5\nVSZ/HzGY84+x80OU+CFK/BAlfogSP0SJH6KM+jZ09+Ph2rWT+hrq027s/3wYHNndlp0fosQPUeKH\nKPFDlPghSvwQJX6IMuff0L9//Lx+8dGyc/6xefjofQ/DcOHozej680/LHReevPdh/N4ZZ+eHKPFD\nlPghSvwQJX6IEj9EiR+izPk3NDYPv3n06+hnx16hvYnpc+tf1q5MzcK/3roy8d3zzfmvP7g3uj71\nGwS2Y+eHKPFDlPghSvwQJX6IEj9EiR+izPl3YMnny0/9xmDy9eAzMsdflp0fosQPUeKHKPFDlPgh\nSvwQZdR3xi05yhuG8WO7Hr29LDs/RIkfosQPUeKHKPFDlPghSvwQZc5/Biz5Gu1LT++Prl8+Wu44\nM+Ps/BAlfogSP0SJH6LED1HihyjxQ5Q5/ymw5Gu07348HF1f8rHkbMfOD1HihyjxQ5T4IUr8ECV+\niBI/RJnznwBTc/xXjx7v6E7+7/PVL4tdm3nZ+SFK/BAlfogSP0SJH6LED1Hihyhz/lNg6tn41w7e\nrV17sv9y9LNT5/WHwZz/rLLzQ5T4IUr8ECV+iBI/RIkfovZWq9XOLnbj3O3dXQyiXnx7trfJ39n5\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oeonZ7nB04OOz9EiR+ixA9R\n4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ\n9R9B08PaIgQVtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1222ecbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  9\n",
      "predicted Label =  9\n",
      "Class probabilities =  [[  1.68720578e-06   4.20459952e-11   2.38611875e-07   1.38741225e-05\n",
      "    7.29068997e-05   1.88692354e-07   2.35165132e-09   6.93742186e-06\n",
      "    1.32321104e-04   9.99771893e-01]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUOKHUOKHUOKHUOKHUOKHUOKHUOKHUP8FJXvjCnw39skAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11384c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  4\n",
      "predicted Label =  4\n",
      "Class probabilities =  [[  2.88184810e-06   1.26839050e-05   1.49038460e-05   7.35788461e-08\n",
      "    9.99852538e-01   5.82827852e-07   1.05791143e-04   5.88020885e-06\n",
      "    3.83620863e-06   7.90232832e-07]]\n",
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ/wCR65T/Wcv1twAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a720b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  1\n",
      "predicted Label =  1\n",
      "Class probabilities =  [[  1.57714880e-04   9.75054562e-01   2.57300126e-04   6.23580010e-04\n",
      "    3.43757347e-06   1.48463741e-05   2.01863671e-07   9.44280904e-03\n",
      "    1.27041861e-02   1.74128788e-03]]\n",
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a77e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  2\n",
      "predicted Label =  2\n",
      "Class probabilities =  [[  5.66266312e-10   2.85997316e-07   9.99745667e-01   2.49856785e-05\n",
      "    2.83391159e-07   4.20790784e-05   2.18781366e-08   2.52788965e-07\n",
      "    1.86559875e-04   4.90352736e-09]]\n",
      "\r",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/BBK/BBK/BBK/BBK/BDqP35e1MWhlLG2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122b8c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  9\n",
      "predicted Label =  9\n",
      "Class probabilities =  [[  2.19677543e-09   5.32710338e-08   7.31317442e-08   1.32005914e-06\n",
      "    1.07770931e-04   1.12509038e-02   5.74989315e-07   2.89723812e-06\n",
      "    1.69961004e-05   9.88619447e-01]]\n"
     ]
    }
   ],
   "source": [
    "# plot 10 randomly selected digits from test dataset\n",
    "plot_digits(model, X_test, y_test, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 79us/step\n",
      "Best Test Loss: 0.071363\n",
      "Best Test Accuracy: 0.978600\n"
     ]
    }
   ],
   "source": [
    "# re-run the accuracy evaluation on the test model using the save best weights\n",
    "get_best_model(filepath, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3 A Simple Convolutional Neural Network: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LeNet model\n",
    "def get_Model(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: the required shape for the keras API\n",
    "    \"\"\"\n",
    "    # kernal_intializer with Truncated Normal std_dev 0.1 and mean 0.0\n",
    "    kernel_initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=None)\n",
    "    # bias_initializer with constant 0.1\n",
    "    bias_initializer = keras.initializers.Constant(value=0.1)\n",
    "    # use the sequential model, which is a linear stack of layers\n",
    "    model = Sequential()\n",
    "    # add a conv layer with 32 filters of kernel_size (5,5), use same padding to keep the dimensions\n",
    "    # use default strides (1,1) and relu function as activaion \n",
    "    model.add(Conv2D(32, (5, 5), padding = \"same\", kernel_initializer = kernel_initializer, \\\n",
    "                     bias_initializer = bias_initializer, \\\n",
    "                     input_shape = input_shape, activation = \"relu\", use_bias = True))\n",
    "    # add a pooling layer with pool_size of (2,2) and default strides of (2,2), \n",
    "    # use same padding to reduce the dimensions to half\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = \"same\"))\n",
    "    # add a conv layer with 64 filters of kernel_size (5,5), use padding to keep the dimensions\n",
    "    # use default strides (1,1) and relu function as activaion \n",
    "    model.add(Conv2D(64, (5, 5), padding = \"same\",  kernel_initializer = kernel_initializer, \\\n",
    "                     bias_initializer = bias_initializer, activation = \"relu\", use_bias = True))\n",
    "    # add a pooling layer with pool_size of (2,2) and default strides of (2,2), \n",
    "    # use same padding to reduce the dimensions to half\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding = \"same\"))\n",
    "    # flatten the vetctor for input to dense layer\n",
    "    model.add(Flatten())\n",
    "    # add a dense layer with 1024 neurons and use relu as activation function after linear layer\n",
    "    model.add(Dense(1024, activation = \"relu\", \\\n",
    "                    kernel_initializer = kernel_initializer, bias_initializer = bias_initializer))\n",
    "    # add dropout with 50% keep rate\n",
    "    model.add(Dropout(0.5))\n",
    "    # add a dense layer with 10 neurons and use softmax function to get class probability\n",
    "    model.add(Dense(10, activation='softmax', kernel_initializer = kernel_initializer, \\\n",
    "                    bias_initializer = bias_initializer))\n",
    "    # use adam optimizer\n",
    "    adam = keras.optimizers.Adam(lr=1e-4)\n",
    "    # fit the model with training data \n",
    "    # I use the validation_split provided by keras API to do test_validation split here, it's much simpler\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "47950/48000 [============================>.] - ETA: 0s - loss: 0.6814 - acc: 0.8349Epoch 00001: val_loss improved from inf to 0.11831, saving model to LeNet.weights.best.hdf5\n",
      "48000/48000 [==============================] - 246s 5ms/step - loss: 0.6810 - acc: 0.8350 - val_loss: 0.1183 - val_acc: 0.9645\n",
      "Epoch 2/12\n",
      " 8300/48000 [====>.........................] - ETA: 3:08 - loss: 0.1836 - acc: 0.9422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d8324afc16c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# train the model on train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LeNet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2f49b61cd234>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, model_name, batch_size, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# fit the model with training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# I use the validation_split provided by keras API to do test_validation split here, it's much simpler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define input shape\n",
    "input_shape = (rows, cols, 1)\n",
    "# get the shaped data\n",
    "X_train, X_test, y_train, y_test = get_data(input_shape)\n",
    "# configure the model\n",
    "model = get_Model(input_shape)\n",
    "# train the model on train dataset\n",
    "filepath, log_dir = train(model, X_train, y_train, \"LeNet\", 50, 12)\n",
    "print (filepath, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "Test Loss: 0.022507\n",
      "Test Accuracy: 0.991700\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model on test dataset\n",
    "evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABY9JREFUeJzt3U2I1HUcx/Edd9IytQwPpbksChIRUfRAD3aqpYgIJKyI\noksPUGmHgo4d7CJYdJAgOph2MzzUIQIP1cWoCCqNpJU0SFwQC3rQWp35d+nYfCecdmd3P6/X9bP/\n/w7Im9/h5+62mqYZAfIsGvYHAIZD/BBK/BBK/BBK/BBK/BBK/BBK/BBK/BCqPZvfbGLRZv+dEGbY\n/u67rf/ydU5+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+\nCCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+\nCCV+CCV+CNUe9gcg128P31LupzadLve3btpT7k9/+VjPbWzzwfLZBE5+CCV+CCV+CCV+CCV+CCV+\nCCV+COWenxnVXjfec3tn+47y2bH2ReX+3dmz5X7Z3qXlns7JD6HED6HED6HED6HED6HED6Fc9TGj\nlrz9R8+t31VeP1uf2VLuyz74bKD3L3ROfgglfgglfgglfgglfgglfgglfgjlnp+BTN99Y7nvW7ez\nWC8on93169pyXzp5qtw75YqTH0KJH0KJH0KJH0KJH0KJH0KJH0K552cgP94/Wu5LWvVdfmXf43fW\nXzDpz2wPwskPocQPocQPocQPocQPocQPocQPodzzU2qPj5X7D5veLPdO0+q5fTV9rnx29OhU/e5y\npR8nP4QSP4QSP4QSP4QSP4QSP4QSP4Ryzx+uvWZ1ud/6/vfl3mm65d4daXpuTx16tHx21cn6ezMY\nJz+EEj+EEj+EEj+EEj+EEj+EctWXbnH9q7U3XjzYddtrP1/Vc7t861/ls/UP/DIoJz+EEj+EEj+E\nEj+EEj+EEj+EEj+Ecs8f7vDzV5T77ReeLfcTnTPlvm/HXT23lUc/LZ9lZjn5IZT4IZT4IZT4IZT4\nIZT4IZT4IZR7/nBbJj4c6PltUxPlvnK3u/y5yskPocQPocQPocQPocQPocQPocQPodzzL3DHX7qt\n3LdcurPPG1rlemDv9eW+euRAn/czLE5+CCV+CCV+CCV+CCV+CCV+CCV+COWefyFYNNpzGrvnWPlo\nd6Qp9zu+fqjc1+6eLPdOuTJMTn4IJX4IJX4IJX4IJX4IJX4I5apvATj6ys09t2831D+y+9zxjeW+\nfPvycu+cPFLuzF1Ofgglfgglfgglfgglfgglfgglfgjlnn8eGF2xotxffmDveb/74/3Xlfv4J/7E\n9kLl5IdQ4odQ4odQ4odQ4odQ4odQ4odQ7vnngZ+euKbcH1z20Xm/e/y938/7WeY3Jz+EEj+EEj+E\nEj+EEj+EEj+EEj+Ecs8/B7THx8r9mxffKPdO0+q5Xb3r2fLZ8c/9vH4qJz+EEj+EEj+EEj+EEj+E\nEj+EctU3Bxx75Mpy7zTdct905N6e2/pXD9fvLlcWMic/hBI/hBI/hBI/hBI/hBI/hBI/hHLPPwtG\nN6wv9z1Pvt7nDfU/0/QLq3puzS+H+rybVE5+CCV+CCV+CCV+CCV+CCV+CCV+COWefxZ0L1la7tcu\nHi33E53T5d7681zPrSmfJJmTH0KJH0KJH0KJH0KJH0KJH0KJH0K5558Htk1NlHv3UP27+eHfOPkh\nlPghlPghlPghlPghlPghlPghlHv+WdB8cbDc71tzQ583nPn/Pgz8w8kPocQPocQPocQPocQPocQP\nocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPocQPoVpN0wz7MwBD\n4OSHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKH\nUOKHUOKHUOKHUOKHUH8D3JqTc1FaJmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121e5f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  1\n",
      "predicted Label =  1\n",
      "Class probabilities =  [[  5.31246833e-08   9.99907970e-01   2.04114571e-07   6.40227177e-11\n",
      "    8.24502858e-05   2.36676789e-09   5.06837353e-07   8.33751346e-06\n",
      "    3.74613364e-07   9.28723409e-08]]\n",
      "\r",
      "1/1 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1139cea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  0\n",
      "predicted Label =  0\n",
      "Class probabilities =  [[  9.99986768e-01   3.40331474e-09   2.10760436e-06   1.26232507e-07\n",
      "    5.44766676e-10   7.19549575e-08   2.08531424e-06   9.36479481e-08\n",
      "    8.77205093e-06   1.14270895e-08]]\n",
      "\r",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n98KGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1221cee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  5\n",
      "predicted Label =  5\n",
      "Class probabilities =  [[  2.14967887e-11   4.60546748e-13   7.51166842e-14   8.17207546e-09\n",
      "    1.92182692e-09   9.99983311e-01   1.35234679e-09   2.47562023e-11\n",
      "    1.66193749e-05   1.95811083e-08]]\n",
      "\r",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122204cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  4\n",
      "predicted Label =  4\n",
      "Class probabilities =  [[  5.89013921e-15   5.71579156e-12   2.23981380e-12   1.41752549e-13\n",
      "    9.99998569e-01   7.48903023e-12   1.88067064e-15   8.01382571e-10\n",
      "    2.31460895e-09   1.47646904e-06]]\n",
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121ac70b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  9\n",
      "predicted Label =  9\n",
      "Class probabilities =  [[  4.87702367e-09   6.48234888e-09   2.54918177e-07   1.76811255e-07\n",
      "    1.27399437e-06   1.41978234e-07   1.44599728e-08   3.18241291e-06\n",
      "    1.84505829e-03   9.98149991e-01]]\n",
      "\r",
      "1/1 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/60CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c9aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  7\n",
      "predicted Label =  7\n",
      "Class probabilities =  [[  2.63259442e-10   5.45231433e-06   2.52802602e-06   5.81041058e-06\n",
      "    2.87223467e-09   1.00891284e-09   1.33731595e-10   9.99985933e-01\n",
      "    1.97025145e-07   2.13688853e-08]]\n",
      "\r",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ6j/A8ORC3EeDBVfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12baac0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  0\n",
      "predicted Label =  0\n",
      "Class probabilities =  [[  9.99998808e-01   2.70872994e-11   1.32567578e-07   1.08013221e-09\n",
      "    1.48381585e-09   1.30564279e-08   3.72185525e-07   6.56545304e-11\n",
      "    4.64929883e-07   2.33622302e-07]]\n",
      "\r",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4odQ4odQ4odQ4odQ4odQ4odQ4odQXwOm9cctHMjofwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1137a2518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  9\n",
      "predicted Label =  9\n",
      "Class probabilities =  [[  2.36120655e-07   2.11691513e-05   1.10751571e-07   1.17189067e-08\n",
      "    2.84616181e-06   1.55246380e-05   6.62068729e-08   1.70036801e-05\n",
      "    1.23775285e-02   9.87565458e-01]]\n",
      "\r",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4hcQ/WfbCKXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1139a0940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  0\n",
      "predicted Label =  0\n",
      "Class probabilities =  [[  9.63135421e-01   3.21892579e-09   1.46699108e-07   1.20656450e-05\n",
      "    5.29966826e-12   3.68300900e-02   1.44635649e-07   2.12713403e-05\n",
      "    6.67854067e-07   1.47068363e-07]]\n",
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b977dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label =  5\n",
      "predicted Label =  5\n",
      "Class probabilities =  [[  1.77590373e-11   5.51858455e-11   2.18745508e-11   3.05388692e-09\n",
      "    3.89272490e-14   9.99562323e-01   1.26326538e-09   1.31010505e-13\n",
      "    4.37635084e-04   1.37231684e-08]]\n"
     ]
    }
   ],
   "source": [
    "# plot 10 randomly selected digits from test dataset\n",
    "plot_digits(model, X_test, y_test, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "Best Test Loss: 0.023861\n",
      "Best Test Accuracy: 0.992600\n"
     ]
    }
   ],
   "source": [
    "# re-run the accuracy evaluation on the test model using the save best weights\n",
    "get_best_model(filepath, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
